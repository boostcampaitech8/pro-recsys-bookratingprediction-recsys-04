import argparse
import ast
from omegaconf import OmegaConf
import pandas as pd
import torch
import torch.optim as optimizer_module
import torch.optim.lr_scheduler as scheduler_module
from src.utils import Logger, Setting
import src.data as data_module
from src.train import train, test
import src.models as model_module
import numpy as np
from sklearn.model_selection import KFold


def main(args, wandb=None):
    Setting.seed_everything(args.seed)

    ######################## LOAD DATA
    datatype = args.model_args[args.model].datatype
    data_load_fn = getattr(data_module, f"{datatype}_data_load")
    data_loader_fn = getattr(data_module, f"{datatype}_data_loader")
    data_split_fn = getattr(data_module, f"{datatype}_data_split")

    print(f"--------------- {args.model} Load Data ---------------")
    # ë°ì´í„° ë¡œë“œëŠ” ê³µí†µ
    original_data = data_load_fn(args)

    ######################## MODE SELECTION
    # ğŸ”¥ [ìˆ˜ì •] args ê°ì²´ì— 'kfold' í‚¤ê°€ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•˜ì—¬ Noneì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©
    kfold_splits = getattr(args, "kfold", None)

    # if args.kfold is not None and args.kfold > 1:  # â¬…ï¸ ì´ ë¶€ë¶„ì„ ì•„ë˜ì²˜ëŸ¼ ë°”ê¿‰ë‹ˆë‹¤.
    if kfold_splits is not None and kfold_splits > 1:

        # ==========================================
        # [MODE 1] K-Fold Ensemble Training Strategy
        # ==========================================
        n_splits = kfold_splits
        kf = KFold(n_splits=n_splits, shuffle=True, random_state=args.seed)
        fold_predicts_list = []

        print(f">>> K-FOLD MODE ENABLED: {n_splits} Folds <<<")

        # í•™ìŠµ ëª¨ë“œì¼ ë•Œë§Œ K-Fold Loop ì§„í–‰
        if not args.predict:
            train_df = original_data[
                "train"
            ]  # ë°ì´í„° êµ¬ì¡° ê°€ì •: {'train': df, 'test': df}

            for fold_idx, (train_idx, valid_idx) in enumerate(kf.split(train_df)):
                print(
                    f"\n\n=============== FOLD {fold_idx+1}/{n_splits} ==============="
                )

                # 1. Fold Split
                fold_train_data = train_df.iloc[train_idx]
                fold_valid_data = train_df.iloc[valid_idx]

                # 2. ë©”íƒ€ë°ì´í„° í¬í•¨í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ êµ¬ì„± (original_dataë¥¼ ë³µì‚¬í•´ì„œ ì‹œì‘)
                target = "rating"

                # ğŸ”¥ [í•µì‹¬ ìˆ˜ì •] original_dataì˜ ëª¨ë“  ë©”íƒ€ë°ì´í„°(field_dims, field_names ë“±)ë¥¼ ë³µì‚¬í•´ì„œ ì‹œì‘
                input_data = original_data.copy()

                # 3. K-Foldë¡œ ë‚˜ëˆˆ ë°ì´í„°ë¡œ train/valid í‚¤ë¥¼ ë®ì–´ì“°ê±°ë‚˜ ì¶”ê°€ (X, y ë¶„ë¦¬)
                input_data["X_train"] = fold_train_data.drop(columns=[target])
                input_data["y_train"] = fold_train_data[target]
                input_data["X_valid"] = fold_valid_data.drop(columns=[target])
                input_data["y_valid"] = fold_valid_data[target]

                # 'test'ì™€ 'field_dims', 'field_names' ë“±ì€ ì´ë¯¸ original_data.copy()ì— í¬í•¨ë¨

                # 4. DataLoader ìƒì„±
                # current_dataì—ëŠ” ì´ì œ DataLoader ê°ì²´ë“¤ì´ ë‹´ê²¨ ë‚˜ì˜´
                current_data = data_loader_fn(args, input_data)

                # 5. [ì•ˆì „ì¥ì¹˜] ëª¨ë¸ ì´ˆê¸°í™”ì— í•„ìš”í•œ ë©”íƒ€ë°ì´í„°ê°€ data_loader_fnì„ ê±°ì¹˜ë©° ì‚¬ë¼ì¡Œì„ ê²½ìš° ë‹¤ì‹œ ë³µêµ¬
                # (NCF, DeepFM ê³„ì—´ ëª¨ë¸ì€ field_dimsì™€ field_namesë¥¼ í•„ìš”ë¡œ í•¨)
                for key in original_data:
                    # 'train' DataFrame ìì²´ëŠ” í•„ìš” ì—†ìœ¼ë¯€ë¡œ ê±´ë„ˆëœ€
                    if key not in current_data and key not in ["train"]:
                        current_data[key] = original_data[key]

                # 6. Logger Setup
                setting = Setting()
                log_path = setting.get_log_path(args)
                logger = Logger(args, log_path)
                logger.save_args()

                # 7. Model Init
                print(
                    f"--------------- INIT {args.model} (Fold {fold_idx+1}) ---------------"
                )
                model = getattr(model_module, args.model)(
                    args.model_args[args.model], current_data
                ).to(args.device)

                if args.train.resume:
                    model.load_state_dict(
                        torch.load(args.train.resume_path, weights_only=True)
                    )

                # 8. Train
                print(
                    f"--------------- {args.model} TRAINING (Fold {fold_idx+1}) ---------------"
                )
                model = train(args, model, current_data, logger, setting)

                # 9. Predict (Inference)
                print(
                    f"--------------- {args.model} PREDICT (Fold {fold_idx+1}) ---------------"
                )
                predicts = test(args, model, current_data, setting)
                fold_predicts_list.append(predicts)

            # Soft Voting
            print(
                f"--------------- Soft Voting Ensemble ({n_splits} Folds) ---------------"
            )
            avg_predicts = np.mean(fold_predicts_list, axis=0)

            # Save
            print(f"--------------- SAVE {args.model} ENSEMBLE PREDICT ---------------")
            submission = pd.read_csv(args.dataset.data_path + "sample_submission.csv")
            submission["rating"] = avg_predicts

            filename = setting.get_submit_filename(args)
            filename = filename.replace(".csv", f"_kfold_{n_splits}.csv")
            print(f"Save Predict: {filename}")
            submission.to_csv(filename, index=False)

        else:
            # ì˜ˆì¸¡ ëª¨ë“œì¸ë° K-Foldë¥¼ í‚¨ ê²½ìš° (ë³´í†µ 5ê°œ ëª¨ë¸ ë¡œë“œí•´ì•¼ í•´ì„œ ë³µì¡í•¨ -> ê²½ê³  í›„ ë‹¨ì¼ ì‹¤í–‰ ì¶”ì²œ)
            print(
                "!!! Warning: Prediction-only mode with K-Fold is not fully supported in this script version."
            )
            print("!!! Please run without --kfold for single model inference.")

    else:
        # ==========================================
        # [MODE 2] Original Single Run Strategy
        # ==========================================
        print(
            f"--------------- {args.model} Train/Valid Split (Original) ---------------"
        )
        data = data_split_fn(args, original_data)
        data = data_loader_fn(args, data)

        ####################### Setting for Log
        setting = Setting()
        if args.predict == False:
            log_path = setting.get_log_path(args)
            logger = Logger(args, log_path)
            logger.save_args()

        ######################## Model
        print(f"--------------- INIT {args.model} ---------------")
        model = getattr(model_module, args.model)(args.model_args[args.model], data).to(
            args.device
        )

        if args.train.resume:
            model.load_state_dict(torch.load(args.train.resume_path, weights_only=True))

        ######################## TRAIN
        if not args.predict:
            print(f"--------------- {args.model} TRAINING ---------------")
            model = train(args, model, data, logger, setting)

        ######################## INFERENCE
        if not args.predict:
            print(f"--------------- {args.model} PREDICT ---------------")
            predicts = test(args, model, data, setting)
        else:
            print(f"--------------- {args.model} PREDICT ---------------")
            predicts = test(args, model, data, setting, args.checkpoint)

        ######################## SAVE PREDICT
        print(f"--------------- SAVE {args.model} PREDICT ---------------")
        submission = pd.read_csv(args.dataset.data_path + "sample_submission.csv")
        submission["rating"] = predicts

        filename = setting.get_submit_filename(args)
        print(f"Save Predict: {filename}")
        submission.to_csv(filename, index=False)


if __name__ == "__main__":

    ######################## BASIC ENVIRONMENT SETUP
    parser = argparse.ArgumentParser(description="parser")
    arg = parser.add_argument
    str2dict = lambda x: {k: int(v) for k, v in (i.split(":") for i in x.split(","))}

    # add basic arguments
    arg(
        "--config",
        "-c",
        "--c",
        type=str,
        help="Configuration íŒŒì¼ì„ ì„¤ì •í•©ë‹ˆë‹¤.",
        required=True,
    )

    # [NEW] K-Fold Argument
    arg(
        "--kfold",
        "-k",
        type=int,
        default=None,
        help="K-Fold í•™ìŠµì„ ìˆ˜í–‰í•˜ë ¤ë©´ fold ê°œìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 5). ì…ë ¥í•˜ì§€ ì•Šìœ¼ë©´ ì¼ë°˜ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.",
    )

    arg(
        "--predict",
        "-p",
        "--p",
        "--pred",
        type=ast.literal_eval,
        help="í•™ìŠµì„ ìƒëµí• ì§€ ì—¬ë¶€ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    )
    arg(
        "--checkpoint",
        "-ckpt",
        "--ckpt",
        type=str,
        help="í•™ìŠµì„ ìƒëµí•  ë•Œ ì‚¬ìš©í•  ëª¨ë¸ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    )
    arg(
        "--model",
        "-m",
        "--m",
        type=str,
        choices=[
            "FM",
            "FFM",
            "DeepFM",
            "NCF",
            "WDN",
            "DCN",
            "Image_FM",
            "Image_DeepFM",
            "Text_FM",
            "Text_DeepFM",
            "ResNet_DeepFM",
        ],
        help="í•™ìŠµ ë° ì˜ˆì¸¡í•  ëª¨ë¸ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    )
    arg(
        "--seed",
        "-s",
        "--s",
        type=int,
        help="ë°ì´í„°ë¶„í•  ë° ëª¨ë¸ ì´ˆê¸°í™” ì‹œ ì‚¬ìš©í•  ì‹œë“œë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    )
    arg(
        "--device",
        "-d",
        "--d",
        type=str,
        choices=["cuda", "cpu", "mps"],
        help="ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    )
    arg(
        "--wandb",
        "--w",
        "-w",
        type=ast.literal_eval,
        help="wandbë¥¼ ì‚¬ìš©í• ì§€ ì—¬ë¶€ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    )
    arg(
        "--wandb_project",
        "--wp",
        "-wp",
        type=str,
        help="wandb í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    )
    arg(
        "--run_name",
        "--rn",
        "-rn",
        "--r",
        "-r",
        type=str,
        help="wandbì—ì„œ ì‚¬ìš©í•  run ì´ë¦„ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    )
    arg("--model_args", "--ma", "-ma", type=ast.literal_eval)
    arg("--dataloader", "--dl", "-dl", type=ast.literal_eval)
    arg("--dataset", "--dset", "-dset", type=ast.literal_eval)
    arg("--optimizer", "-opt", "--opt", type=ast.literal_eval)
    arg("--loss", "-l", "--l", type=str)
    arg("--lr_scheduler", "-lr", "--lr", type=ast.literal_eval)
    arg("--metrics", "-met", "--met", type=ast.literal_eval)
    arg("--train", "-t", "--t", type=ast.literal_eval)

    args = parser.parse_args()

    ######################## Config with yaml
    config_args = OmegaConf.create(vars(args))
    config_yaml = OmegaConf.load(args.config) if args.config else OmegaConf.create()

    # args ìš°ì„  ì ìš©
    for key in config_args.keys():
        if config_args[key] is not None:
            config_yaml[key] = config_args[key]

    # ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ì •ë³´ ì‚­ì œ
    if config_yaml.predict == False:
        del config_yaml.checkpoint
        if config_yaml.wandb == False:
            del config_yaml.wandb_project, config_yaml.run_name
        config_yaml.model_args = OmegaConf.create(
            {config_yaml.model: config_yaml.model_args[config_yaml.model]}
        )
        config_yaml.optimizer.args = {
            k: v
            for k, v in config_yaml.optimizer.args.items()
            if k
            in getattr(
                optimizer_module, config_yaml.optimizer.type
            ).__init__.__code__.co_varnames
        }
        if config_yaml.lr_scheduler.use == False:
            del config_yaml.lr_scheduler.type, config_yaml.lr_scheduler.args
        else:
            config_yaml.lr_scheduler.args = {
                k: v
                for k, v in config_yaml.lr_scheduler.args.items()
                if k
                in getattr(
                    scheduler_module, config_yaml.lr_scheduler.type
                ).__init__.__code__.co_varnames
            }
        if config_yaml.train.resume == False:
            del config_yaml.train.resume_path

    # Configuration ì¶œë ¥
    print(OmegaConf.to_yaml(config_yaml))

    ######################## W&B
    if args.wandb:
        import wandb

        wandb.init(
            project=config_yaml.wandb_project,
            config=OmegaConf.to_container(config_yaml, resolve=True),
            name=config_yaml.run_name if config_yaml.run_name else None,
            notes=config_yaml.memo if hasattr(config_yaml, "memo") else None,
            tags=[config_yaml.model],
            resume="allow",
        )
        config_yaml.run_href = wandb.run.get_url()
        wandb.run.log_code("./src")

    ######################## MAIN
    main(config_yaml)

    if args.wandb:
        wandb.finish()
